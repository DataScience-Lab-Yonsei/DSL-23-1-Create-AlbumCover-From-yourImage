{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ2cUVLeG3AR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opNoVj9DgvxJ",
        "outputId": "67ad0171-6b2b-43a5-e8e2-bd011c5419a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t94u9RAQNNEO"
      },
      "outputs": [],
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/모델링(앨범커버만들기)/CelebA/Img/img_align_celeba.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1bK3RYdObru"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_03YeQFOkKg"
      },
      "outputs": [],
      "source": [
        "celeba = sorted(glob.glob('/content/img_align_celeba/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYWIbBEaahMx"
      },
      "outputs": [],
      "source": [
        "trot = sorted(glob.glob('/content/drive/MyDrive/Colab Notebooks/모델링(앨범커버만들기)/new_album_image/trot/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEQrYBaDUizP"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q27aftV-i8WN"
      },
      "outputs": [],
      "source": [
        "random.seed(9999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9gNhIBiTmk1"
      },
      "outputs": [],
      "source": [
        "celeba_list = []\n",
        "\n",
        "for _ in range(2000):\n",
        "  celeba_list.append(celeba[random.randrange(0, len(celeba))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# celeba 5000개 사용용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6K24sS1QPgE"
      },
      "outputs": [],
      "source": [
        "celeba_test_count = round(len(celeba_list) * 0.2)\n",
        "# rap_test_count = round(len(rap) * 0.2)\n",
        "trot_test_count = round(len(trot) * 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kr92kZdRmbQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def split(img_list, test_count, train_path, test_path):\n",
        "\n",
        "  test_files = []\n",
        "  for i in random.sample(img_list, test_count):\n",
        "    test_files.append(i)\n",
        "\n",
        "  train_files = [x for x in img_list if x not in test_files]\n",
        "\n",
        "\n",
        "  for k in train_files:\n",
        "    shutil.copy(k, train_path)\n",
        "\n",
        "  for c in test_files:\n",
        "    shutil.copy(c, test_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_no4AElXDwY"
      },
      "outputs": [],
      "source": [
        "train_celeba_path = '/content/train/celeba'\n",
        "test_celeba_path = '/content/test/celeba'\n",
        "\n",
        "# train_rap_path = '/content/train/rap'\n",
        "#test_rap_path = '/content/test/rap'\n",
        "\n",
        "train_trot_path = '/content/train/trot'\n",
        "test_trot_path = '/content/test/trot'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(train_celeba_path, exist_ok = True)\n",
        "os.makedirs(test_celeba_path, exist_ok = True)\n",
        "\n",
        "# os.makedirs(train_rap_path, exist_ok = True)\n",
        "# os.makedirs(test_rap_path, exist_ok = True)\n",
        "\n",
        "os.makedirs(train_trot_path, exist_ok = True)\n",
        "os.makedirs(test_trot_path, exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WRhNsr_YJny"
      },
      "outputs": [],
      "source": [
        "split(celeba_list, celeba_test_count, train_celeba_path, test_celeba_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7ZcVgEJcKNG"
      },
      "outputs": [],
      "source": [
        "split(trot, trot_test_count, train_trot_path, test_trot_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMQwm1HzUte",
        "outputId": "2499894a-3939-4e3a-95f8-00acc25619b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋 A의 개수: 1592\n",
            "학습 데이터셋 B의 개수: 621\n",
            "테스트 데이터셋 A의 개수: 400\n",
            "테스트 데이터셋 B의 개수: 155\n"
          ]
        }
      ],
      "source": [
        "print(\"학습 데이터셋 A의 개수:\", len(next(os.walk('/content/train/celeba'))[2]))\n",
        "print(\"학습 데이터셋 B의 개수:\", len(next(os.walk('/content/train/trot'))[2]))\n",
        "print(\"테스트 데이터셋 A의 개수:\", len(next(os.walk('/content/test/celeba'))[2]))\n",
        "print(\"테스트 데이터셋 B의 개수:\", len(next(os.walk('/content/test/trot'))[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5k8vpztZB_u"
      },
      "outputs": [],
      "source": [
        "my_transform=transforms.Compose([\n",
        "                              transforms.Resize((400, 400)),\n",
        "                              transforms.RandomCrop((400, 400)),\n",
        "                               transforms.RandomHorizontalFlip(),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJA05xcwZN4x"
      },
      "outputs": [],
      "source": [
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEjmNPkUegcR"
      },
      "outputs": [],
      "source": [
        "# 흑백 이미지를 색상 이미지(R/G/B 채널)로 변환하기 위한 함수\n",
        "def to_rgb(image):\n",
        "    rgb_image = Image.new(\"RGB\", image.size)\n",
        "    rgb_image.paste(image)\n",
        "    return rgb_image\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, mode=\"train\"): #root는 train, test dataset\n",
        "        self.transform = transform\n",
        "\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, f\"{mode}/celeba\") + \"/*.jpg\"))\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, f\"{mode}/trot\") + \"/*.jpg\"))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_A = Image.open(self.files_A[index % len(self.files_A)])\n",
        "        img_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]) # img_B는 랜덤하게 샘플링\n",
        "\n",
        "        # 만약 흑백(grayscale) 이미지라면 RGB 채널 이미지로 변환\n",
        "        if img_A.mode != \"RGB\":\n",
        "            img_A = to_rgb(img_A)\n",
        "        if img_B.mode != \"RGB\":\n",
        "            img_B = to_rgb(img_B)\n",
        "\n",
        "        img_A = self.transform(img_A)\n",
        "        img_B = self.transform(img_B)\n",
        "\n",
        "        return {\"A\": img_A, \"B\": img_B}\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JcQrff2oXuI"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageDataset(root = \"/content\", transform=my_transform)\n",
        "test_dataset = ImageDataset(root = \"/content\", transform=my_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JhnA7v0fWdJ"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_glc7jfOf1ar"
      },
      "outputs": [],
      "source": [
        "# 잔여 블록(Residual Block) 모듈 정의\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # 채널(channel) 크기는 그대로 유지\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3),\n",
        "            nn.InstanceNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3),\n",
        "            nn.InstanceNorm2d(in_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "# ResNet 기반의 생성자(Generator) 아키텍처\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        channels = input_shape[0] # 입력 이미지의 채널 수: 3\n",
        "\n",
        "        # 초기 콘볼루션 블록(Convolution Block) 레이어\n",
        "        out_channels = 64\n",
        "        model = [nn.ReflectionPad2d(channels)]\n",
        "        model.append(nn.Conv2d(channels, out_channels, kernel_size=7))\n",
        "        model.append(nn.InstanceNorm2d(out_channels))\n",
        "        model.append(nn.ReLU(inplace=True))\n",
        "        in_channels = out_channels\n",
        "\n",
        "        # 다운샘플링(Downsampling)\n",
        "        for _ in range(2):\n",
        "            out_channels *= 2\n",
        "            model.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)) # 너비와 높이가 2배씩 감소\n",
        "            model.append(nn.InstanceNorm2d(out_channels))\n",
        "            model.append(nn.ReLU(inplace=True))\n",
        "            in_channels = out_channels\n",
        "        # 출력: [256 X (4배 감소한 높이) X (4배 감소한 너비)]\n",
        "\n",
        "        # 인코더와 디코더의 중간에서 Residual Blocks 사용 (차원은 유지)\n",
        "        for _ in range(num_residual_blocks):\n",
        "            model.append(ResidualBlock(out_channels))\n",
        "\n",
        "        # 업샘플링(Upsampling)\n",
        "        for _ in range(2):\n",
        "            out_channels //= 2\n",
        "            model.append(nn.Upsample(scale_factor=2)) # 너비와 높이가 2배씩 증가\n",
        "            model.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)) # 너비와 높이는 그대로\n",
        "            model.append(nn.InstanceNorm2d(out_channels))\n",
        "            model.append(nn.ReLU(inplace=True))\n",
        "            in_channels = out_channels\n",
        "        # 출력: [256 X (4배 증가한 높이) X (4배 증가한 너비)]\n",
        "\n",
        "        # 출력 콘볼루션 블록(Convolution Block) 레이어\n",
        "        model.append(nn.ReflectionPad2d(channels))\n",
        "        model.append(nn.Conv2d(out_channels, channels, kernel_size=7))\n",
        "        model.append(nn.Tanh())\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        channels, height, width = input_shape\n",
        "\n",
        "        # 콘볼루션 블록(Convolution Block) 모듈 정의\n",
        "        def discriminator_block(in_channels, out_channels, normalize=True):\n",
        "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)] # 너비와 높이가 2배씩 감소\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_channels))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 64, normalize=False), # 출력: [64 X 128 X 128]\n",
        "            *discriminator_block(64, 128), # 출력: [128 X 64 X 64]\n",
        "            *discriminator_block(128, 256), # 출력: [256 X 32 X 32]\n",
        "            *discriminator_block(256, 512), # 출력: [512 X 16 X 16]\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, padding=1) # 출력: [1 X 16 X 16]\n",
        "        )\n",
        "        # 최종 출력: [1 X (16배 감소한 높이) X (16배 감소한 너비)]\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_pA0rPpf5BV"
      },
      "outputs": [],
      "source": [
        "# 이미지 버퍼(Buffer) 클래스\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=50):\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    # 새로운 이미지를 삽입하고, 이전에 삽입되었던 이미지를 반환하는 함수\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            # 아직 버퍼가 가득 차지 않았다면, 현재 삽입된 데이터를 반환\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            # 버퍼가 가득 찼다면, 이전에 삽입되었던 이미지를 랜덤하게 반환\n",
        "            else:\n",
        "                if random.uniform(0, 1) > 0.5: # 확률은 50%\n",
        "                    i = random.randint(0, self.max_size - 1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element # 버퍼에 들어 있는 이미지 교체\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return)\n",
        "\n",
        "\n",
        "# 시간이 지남에 따라 학습률(learning rate)을 감소시키는 클래스\n",
        "class LambdaLR:\n",
        "    def __init__(self, n_epochs, decay_start_epoch):\n",
        "        self.n_epochs = n_epochs # 전체 epoch\n",
        "        self.decay_start_epoch = decay_start_epoch # 학습률 감소가 시작되는 epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "\n",
        "# 가중치 초기화를 위한 함수 정의\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if hasattr(m, \"bias\") and m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "\n",
        "# 생성자(generator)와 판별자(discriminator) 초기화\n",
        "G_AB = GeneratorResNet(input_shape=(3, 256, 256), num_residual_blocks=9)\n",
        "G_BA = GeneratorResNet(input_shape=(3, 256, 256), num_residual_blocks=9)\n",
        "D_A = Discriminator(input_shape=(3, 256, 256))\n",
        "D_B = Discriminator(input_shape=(3, 256, 256))\n",
        "\n",
        "G_AB.cuda()\n",
        "G_BA.cuda()\n",
        "D_A.cuda()\n",
        "D_B.cuda()\n",
        "\n",
        "# 가중치(weights) 초기화\n",
        "G_AB.apply(weights_init_normal)\n",
        "G_BA.apply(weights_init_normal)\n",
        "D_A.apply(weights_init_normal)\n",
        "D_B.apply(weights_init_normal)\n",
        "\n",
        "# 손실 함수(loss function)\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "criterion_GAN.cuda()\n",
        "criterion_cycle.cuda()\n",
        "criterion_identity.cuda()\n",
        "\n",
        "n_epochs = 100 # 학습의 횟수(epoch) 설정\n",
        "decay_epoch = 20 # 학습률 감소가 시작되는 epoch 설정\n",
        "lr = 0.0002 # 학습률(learning rate) 설정\n",
        "\n",
        "# 생성자와 판별자를 위한 최적화 함수\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A  = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# 학습률(learning rate) 업데이트 스케줄러 초기화\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "MyEBHobKyPcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "a-7gxEjtf_VI",
        "outputId": "dfc09f2f-22c3-4d2e-9e67-362b44233365"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4c8869587971>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Identity 손실(loss) 값 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss_identity_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_BA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss_identity_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_AB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss_identity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_identity_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_identity_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-3424af0b85ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-3424af0b85ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_no_batch_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_instance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36m_apply_instance_norm\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_instance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         return F.instance_norm(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             self.training or not self.track_running_stats, self.momentum, self.eps)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   2493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \u001b[0m_verify_spatial_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m     return torch.instance_norm(\n\u001b[0m\u001b[1;32m   2496\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 14.42 GiB already allocated; 18.81 MiB free; 14.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "sample_interval = 100 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
        "\n",
        "lambda_cycle = 10 # Cycle 손실 가중치(weight) 파라미터\n",
        "lambda_identity = 5 # Identity 손실 가중치(weight) 파라미터\n",
        "\n",
        "# 이전에 생성된 이미지 데이터를 포함하고 있는 버퍼(buffer) 객체\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        # 모델의 입력(input) 데이터 불러오기\n",
        "        real_A = batch[\"B\"].cuda()\n",
        "        real_B = batch[\"A\"].cuda()\n",
        "\n",
        "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성 (너바와 높이를 16씩 나눈 크기)\n",
        "        real = torch.cuda.FloatTensor(real_A.size(0), 1, 25, 25).fill_(1.0) # 진짜(real): 1\n",
        "        fake = torch.cuda.FloatTensor(real_A.size(0), 1, 25, 25).fill_(0.0) # 가짜(fake): 0\n",
        "\n",
        "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
        "        G_AB.train()\n",
        "        G_BA.train()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity 손실(loss) 값 계산\n",
        "        loss_identity_A = criterion_identity(G_BA(real_A), real_A)\n",
        "        loss_identity_B = criterion_identity(G_AB(real_B), real_B)\n",
        "        loss_identity = (loss_identity_A + loss_identity_B) / 2\n",
        "\n",
        "        # GAN 손실(loss) 값 계산\n",
        "        fake_B = G_AB(real_A)\n",
        "        fake_A = G_BA(real_B)\n",
        "        loss_GAN_AB = criterion_GAN(D_B(fake_B), real)\n",
        "        loss_GAN_BA = criterion_GAN(D_A(fake_A), real)\n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "        # Cycle 손실(loss) 값 계산\n",
        "        recover_A = G_BA(fake_B)\n",
        "        recover_B = G_AB(fake_A)\n",
        "        loss_cycle_A = criterion_cycle(recover_A, real_A)\n",
        "        loss_cycle_B = criterion_cycle(recover_B, real_B)\n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "        # 최종적인 손실(loss)\n",
        "        loss_G = loss_GAN + lambda_cycle * loss_cycle + lambda_identity * loss_identity\n",
        "\n",
        "        # 생성자(generator) 업데이트\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        \"\"\" 판별자(discriminator) A를 학습합니다. \"\"\"\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real 손실(loss): 원본 이미지를 원본으로 판별하도록\n",
        "        loss_real = criterion_GAN(D_A(real_A), real)\n",
        "\n",
        "        # Fake 손실(loss): 가짜 이미지를 가짜로 판별하도록\n",
        "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
        "        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n",
        "\n",
        "        # 최종적인 손실(loss)\n",
        "        loss_D_A = (loss_real + loss_fake) / 2\n",
        "\n",
        "        # 판별자(discriminator) 업데이트\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        \"\"\" 판별자(discriminator) B를 학습합니다. \"\"\"\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # Real 손실(loss): 원본 이미지를 원본으로 판별하도록\n",
        "        loss_real = criterion_GAN(D_B(real_B), real)\n",
        "\n",
        "        # Fake 손실(loss): 가짜 이미지를 가짜로 판별하도록\n",
        "        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
        "        loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n",
        "\n",
        "        # 최종적인 손실(loss)\n",
        "        loss_D_B = (loss_real + loss_fake) / 2\n",
        "\n",
        "        # 판별자(discriminator) 업데이트\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        loss_D = (loss_D_A + loss_D_B) / 2\n",
        "\n",
        "        done = epoch * len(train_dataloader) + i\n",
        "        if done % sample_interval == 0:\n",
        "            G_AB.eval()\n",
        "            G_BA.eval()\n",
        "            imgs = next(iter(test_dataloader)) # 5개의 이미지를 추출해 생성\n",
        "            real_A = imgs[\"B\"].cuda()\n",
        "            real_B = imgs[\"A\"].cuda()\n",
        "            fake_B = G_AB(real_A)\n",
        "            fake_A = G_BA(real_B)\n",
        "            # X축을 따라 각각의 그리디 이미지 생성\n",
        "            real_A = make_grid(real_A, nrow=4, normalize=True)\n",
        "            real_B = make_grid(real_B, nrow=4, normalize=True)\n",
        "            fake_A = make_grid(fake_A, nrow=4, normalize=True)\n",
        "            fake_B = make_grid(fake_B, nrow=4, normalize=True)\n",
        "            # 각각의 격자 이미지를 높이(height)를 기준으로 연결하기 \n",
        "            image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
        "            save_image(image_grid, f\"{done}.png\", normalize=False)\n",
        "            print(f\"[Done {i}/{len(train_dataloader)}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
        "\n",
        "    # 학습률(learning rate)\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_A.step()\n",
        "    lr_scheduler_D_B.step()\n",
        "\n",
        "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
        "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {loss_D.item():.6f}] [G identity loss: {loss_identity.item():.6f}, adv loss: {loss_GAN.item()}, cycle loss: {loss_cycle.item()}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
        "\n",
        "    # 하나의 epoch이 끝날 때마다 모델 파라미터 저장\n",
        "    torch.save({\n",
        "            'epoch': n_epochs,\n",
        "            'model_state_dict': G_AB.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_G.state_dict(),\n",
        "            'loss': loss_G,\n",
        "            }, \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_G_AB_1.pt\")\n",
        "    torch.save({\n",
        "            'epoch': n_epochs,\n",
        "            'model_state_dict': G_BA.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_G.state_dict(),\n",
        "            'loss': loss_G,\n",
        "            }, \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_G_BA_1.pt\")\n",
        "    torch.save({\n",
        "            'epoch': n_epochs,\n",
        "            'model_state_dict': D_A.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_D_A.state_dict(),\n",
        "            'loss': loss_D_A,\n",
        "            }, \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_D_A_1.pt\")\n",
        "    torch.save({\n",
        "            'epoch': n_epochs,\n",
        "            'model_state_dict': D_B.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_D_B.state_dict(),\n",
        "            'loss': loss_D_B,\n",
        "            }, \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_D_B_1.pt\")\n",
        "    print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXYXWnDl9d9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-_7q-w-Y_k"
      },
      "outputs": [],
      "source": [
        "# 모델 파라미터 저장\n",
        "torch.save(G_AB.state_dict(), \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_G_AB.pt\")\n",
        "torch.save(G_BA.state_dict(), \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_G_BA.pt\")\n",
        "torch.save(D_A.state_dict(), \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_D_A.pt\")\n",
        "torch.save(D_B.state_dict(), \"/content/drive/MyDrive/개인별 실습/유선재 - Pixel R.N.N.(Auto-Regressive)/cycleGAN/face2melon_D_B.pt\")\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md2mKDqZt-GE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 생성자(generator)와 판별자(discriminator) 초기화\n",
        "G_AB = GeneratorResNet(input_shape=(3, 256, 256), num_residual_blocks=9)\n",
        "G_BA = GeneratorResNet(input_shape=(3, 256, 256), num_residual_blocks=9)\n",
        "D_A = Discriminator(input_shape=(3, 256, 256))\n",
        "D_B = Discriminator(input_shape=(3, 256, 256))\n",
        "\n",
        "G_AB.cuda()\n",
        "G_BA.cuda()\n",
        "D_A.cuda()\n",
        "D_B.cuda()\n",
        "\n",
        "G_AB.load_state_dict(torch.load(\"/content/drive/MyDrive/선재/G_AB.pt\"))\n",
        "G_BA.load_state_dict(torch.load(\"/content/drive/MyDrive/선재/G_BA.pt\"))\n",
        "D_A.load_state_dict(torch.load(\"/content/drive/MyDrive/선재/D_A.pt\"))\n",
        "D_B.load_state_dict(torch.load(\"/content/drive/MyDrive/선재/D_B.pt\"))\n",
        "\n",
        "G_AB.eval();\n",
        "G_BA.eval();\n",
        "D_A.eval();\n",
        "D_B.eval();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_AB"
      ],
      "metadata": {
        "id": "33PApGBfwWhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a19B-5W--cNn"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "imgs = next(iter(test_dataloader)) # 5개의 이미지를 추출해 생성\n",
        "real_A = imgs[\"B\"].cuda()\n",
        "real_B = imgs[\"A\"].cuda()\n",
        "fake_B = G_AB(real_A)\n",
        "fake_A = G_BA(real_B)\n",
        "# X축을 따라 각각의 그리디 이미지 생성\n",
        "real_A = make_grid(real_A, nrow=4, normalize=True)\n",
        "real_B = make_grid(real_B, nrow=4, normalize=True)\n",
        "fake_A = make_grid(fake_A, nrow=4, normalize=True)\n",
        "fake_B = make_grid(fake_B, nrow=4, normalize=True)\n",
        "# 각각의 격자 이미지를 높이(height)를 기준으로 연결하기 \n",
        "image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
        "save_image(image_grid, f\"result.png\", normalize=False)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrGiUSJ2-dv3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image('result.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}